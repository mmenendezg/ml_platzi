{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi Algorithm with Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from conllu import parse_incr\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import treebank\n",
    "from nltk.tag import hmm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mmenendezg/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/mmenendezg/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"treebank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCORA_PATH = \"data/UD_Spanish-AnCora/es_ancora-ud-dev.conllu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_prob_dict = np.load(\"npy_files/transition_hmm.npy\", allow_pickle=True).item()\n",
    "emission_prob_dict = np.load(\"npy_files/emission_hmm.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_set = sorted(set([w.split(\"|\")[1] for w in list(emission_prob_dict.keys())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ': 0,\n",
       " 'ADP': 1,\n",
       " 'ADV': 2,\n",
       " 'AUX': 3,\n",
       " 'CCONJ': 4,\n",
       " 'DET': 5,\n",
       " 'INTJ': 6,\n",
       " 'NOUN': 7,\n",
       " 'NUM': 8,\n",
       " 'PART': 9,\n",
       " 'PRON': 10,\n",
       " 'PROPN': 11,\n",
       " 'PUNCT': 12,\n",
       " 'SCONJ': 13,\n",
       " 'SYM': 14,\n",
       " 'VERB': 15,\n",
       " '_': 16}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_state_dict = {}\n",
    "for i, state in enumerate(state_set):\n",
    "    tag_state_dict[state] = i\n",
    "tag_state_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial distribution of hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = []\n",
    "data_file = open(ANCORA_PATH, \"r\", encoding=\"utf-8\")\n",
    "count = 0\n",
    "init_tag_state_prob = {} #\\rho_i^(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DET': 0.36275695284159615,\n",
       " 'PROPN': 0.1124546553808948,\n",
       " 'ADP': 0.15538089480048367,\n",
       " 'PRON': 0.06348246674727932,\n",
       " 'SCONJ': 0.02418379685610641,\n",
       " 'ADV': 0.056831922611850064,\n",
       " 'PUNCT': 0.08222490931076179,\n",
       " 'VERB': 0.021160822249093107,\n",
       " 'ADJ': 0.010882708585247884,\n",
       " 'CCONJ': 0.032648125755743655,\n",
       " 'NOUN': 0.02720677146311971,\n",
       " '_': 0.009068923821039904,\n",
       " 'INTJ': 0.0006045949214026602,\n",
       " 'AUX': 0.019347037484885126,\n",
       " 'NUM': 0.01995163240628779,\n",
       " 'PART': 0.0018137847642079807}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tokenlist in parse_incr(data_file):\n",
    "    count += 1\n",
    "    tag = tokenlist[0][\"upos\"]\n",
    "    if tag in init_tag_state_prob.keys():\n",
    "        init_tag_state_prob[tag] += 1\n",
    "    else:\n",
    "        init_tag_state_prob[tag] = 1\n",
    "\n",
    "for key in init_tag_state_prob.keys():\n",
    "    init_tag_state_prob[key] /= count\n",
    "\n",
    "init_tag_state_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that all probs sum 1\n",
    "np.array([value for value in init_tag_state_prob.values()]).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction of the Viterbi Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada una secuencia de palabras $\\{p_1, p_2, \\dots, p_n \\}$, y un conjunto de categorias gramaticales dadas por la convención `upos`, se considera la matriz de probabilidades de Viterbi así:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c c}\n",
    "\\begin{array}{c c c c}\n",
    "\\text{ADJ} \\\\\n",
    "\\text{ADV}\\\\\n",
    "\\text{PRON} \\\\\n",
    "\\vdots \\\\\n",
    "{}\n",
    "\\end{array} \n",
    "&\n",
    "\\left[\n",
    "\\begin{array}{c c c c}\n",
    "\\nu_1(\\text{ADJ}) & \\nu_2(\\text{ADJ}) & \\dots  & \\nu_n(\\text{ADJ})\\\\\n",
    "\\nu_1(\\text{ADV}) & \\nu_2(\\text{ADV}) & \\dots  & \\nu_n(\\text{ADV})\\\\ \n",
    "\\nu_1(\\text{PRON}) & \\nu_2(\\text{PRON}) & \\dots  & \\nu_n(\\text{PRON})\\\\\n",
    "\\vdots & \\vdots & \\dots & \\vdots \\\\ \\hdashline\n",
    "p_1 & p_2 & \\dots & p_n \n",
    "\\end{array}\n",
    "\\right] \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Donde las probabilidades de la primera columna (para una categoria $i$) están dadas por: \n",
    "\n",
    "$$\n",
    "\\nu_1(i) = \\underbrace{\\rho_i^{(0)}}_{\\text{probabilidad inicial}} \\times \\underbrace{P(p_1 \\vert i)}_{\\text{emisión}}\n",
    "$$\n",
    "\n",
    "luego, para la segunda columna (dada una categoria $j$) serán: \n",
    "\n",
    "$$\n",
    "\\nu_2(j) = \\max_i \\{ \\nu_1(i) \\times \\underbrace{P(j \\vert i)}_{\\text{transición}} \\times \\underbrace{P(p_2 \\vert j)}_{\\text{emisión}} \\}\n",
    "$$\n",
    "\n",
    "así, en general las probabilidades para la columna $t$ estarán dadas por: \n",
    "\n",
    "$$\n",
    "\\nu_{t}(j) = \\max_i \\{ \\overbrace{\\nu_{t-1}(i)}^{\\text{estado anterior}} \\times \\underbrace{P(j \\vert i)}_{\\text{transición}} \\times \\underbrace{P(p_t \\vert j)}_{\\text{emisión}} \\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Viterbi Matrix\n",
    "\n",
    "\n",
    "def viterbi_matrix(\n",
    "    sequence,\n",
    "    transition_prob_dict=transition_prob_dict,\n",
    "    emission_prob_dict=emission_prob_dict,\n",
    "    tag_state_dict=tag_state_dict,\n",
    "    init_tag_state_prob=init_tag_state_prob,\n",
    "):\n",
    "    seq = word_tokenize(sequence.lower())\n",
    "    viterbi_prob = np.zeros((17, len(seq)))\n",
    "\n",
    "    # Initialize the first column\n",
    "    for key in tag_state_dict.keys():\n",
    "        tag_row = tag_state_dict[key]\n",
    "        word_tag = f\"{seq[0]}|{key}\"\n",
    "        if word_tag in emission_prob_dict.keys():\n",
    "            viterbi_prob[tag_row, 0] = (\n",
    "                init_tag_state_prob[key] * emission_prob_dict[word_tag]\n",
    "            )\n",
    "\n",
    "    # Probs of the following columns\n",
    "    for col in range(1, len(seq)):\n",
    "        for key in tag_state_dict.keys():\n",
    "            tag_row = tag_state_dict[key]\n",
    "            word_tag = f\"{seq[col]}|{key}\"\n",
    "            if word_tag in emission_prob_dict.keys():\n",
    "                possible_prob = []\n",
    "                for key_2 in tag_state_dict.keys():\n",
    "                    tag_row_2 = tag_state_dict[key_2]\n",
    "                    tag_prev_tag = f\"{key}|{key_2}\"\n",
    "                    if tag_prev_tag in transition_prob_dict.keys():\n",
    "                        if viterbi_prob[tag_row_2, col - 1] > 0:\n",
    "                            possible_prob.append(\n",
    "                                viterbi_prob[tag_row_2, col - 1]\n",
    "                                * transition_prob_dict[tag_prev_tag]\n",
    "                                * emission_prob_dict[word_tag]\n",
    "                            )\n",
    "                viterbi_prob[tag_row, col] = max(possible_prob) if possible_prob else 0\n",
    "\n",
    "    return viterbi_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.12461736, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.00034087, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.00015494, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = viterbi_matrix(\"El mundo es pequeño\")\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Viterbi Matrix\n",
    "\n",
    "\n",
    "def viterbi_tags(\n",
    "    sequence,\n",
    "    transition_prob_dict=transition_prob_dict,\n",
    "    emission_prob_dict=emission_prob_dict,\n",
    "    tag_state_dict=tag_state_dict,\n",
    "    init_tag_state_prob=init_tag_state_prob,\n",
    "):\n",
    "    seq = word_tokenize(sequence.lower())\n",
    "    viterbi_prob = np.zeros((17, len(seq)))\n",
    "\n",
    "    # Initialize the first column\n",
    "    for key in tag_state_dict.keys():\n",
    "        tag_row = tag_state_dict[key]\n",
    "        word_tag = f\"{seq[0]}|{key}\"\n",
    "        if word_tag in emission_prob_dict.keys():\n",
    "            viterbi_prob[tag_row, 0] = (\n",
    "                init_tag_state_prob[key] * emission_prob_dict[word_tag]\n",
    "            )\n",
    "\n",
    "    # Probs of the following columns\n",
    "    for col in range(1, len(seq)):\n",
    "        for key in tag_state_dict.keys():\n",
    "            tag_row = tag_state_dict[key]\n",
    "            word_tag = f\"{seq[col]}|{key}\"\n",
    "            if word_tag in emission_prob_dict.keys():\n",
    "                possible_prob = []\n",
    "                for key_2 in tag_state_dict.keys():\n",
    "                    tag_row_2 = tag_state_dict[key_2]\n",
    "                    tag_prev_tag = f\"{key}|{key_2}\"\n",
    "                    if tag_prev_tag in transition_prob_dict.keys():\n",
    "                        if viterbi_prob[tag_row_2, col - 1] > 0:\n",
    "                            possible_prob.append(\n",
    "                                viterbi_prob[tag_row_2, col - 1]\n",
    "                                * transition_prob_dict[tag_prev_tag]\n",
    "                                * emission_prob_dict[word_tag]\n",
    "                            )\n",
    "                viterbi_prob[tag_row, col] = max(possible_prob) if possible_prob else 0\n",
    "    \n",
    "    # Get the sequence of tags \n",
    "    \n",
    "    res=[]\n",
    "    for i, p in enumerate(seq):\n",
    "        for tag in tag_state_dict.keys():\n",
    "            if tag_state_dict[tag] == np.argmax(viterbi_prob[:, i]):\n",
    "                res.append((p, tag))\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yo', 'PRON'),\n",
       " ('no', 'ADJ'),\n",
       " ('me', 'ADJ'),\n",
       " ('llamo', 'ADJ'),\n",
       " ('marlon', 'ADJ')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi_tags(\"Yo no me llamo Marlon\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training HMM with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = treebank.tagged_sents()[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')], [('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'NNP'), ('publishing', 'VBG'), ('group', 'NN'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = hmm.HiddenMarkovModelTagger.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'), ('will', 'MD'), ('get', 'VB'), ('old', 'JJ')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(\"I will get old\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t1/ny5zn1h15gq9cn6lhptkn_f00000gn/T/ipykernel_42353/1269393345.py:3: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  tagger.evaluate(valid_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9040199439077594"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training accuracy\n",
    "valid_data = treebank.tagged_sents()[3000:3500]\n",
    "tagger.evaluate(valid_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "\n",
    "Train a `HiddenMarkovModelTagger` using the `UD_Spanish_AnCora` corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ancora_corpus = open(ANCORA_PATH, \"r\", encoding=\"utf-8\")\n",
    "\n",
    "tagtype = \"upos\"\n",
    "tagged_corpus = []\n",
    "for tokenlist in parse_incr(ancora_corpus):\n",
    "    tagged_sentence = []\n",
    "    for token in tokenlist:\n",
    "        tagged_word = (token[\"form\"], token[tagtype])\n",
    "        tagged_sentence.append(tagged_word)\n",
    "    tagged_corpus.append(tagged_sentence)\n",
    "\n",
    "len(tagged_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "train_data, test_data = train_test_split(tagged_corpus, train_size=0.8, random_state=1992, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = hmm.HiddenMarkovModelTagger.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t1/ny5zn1h15gq9cn6lhptkn_f00000gn/T/ipykernel_42353/3521729379.py:1: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  tagger.evaluate(train_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9699498791730063"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.evaluate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t1/ny5zn1h15gq9cn6lhptkn_f00000gn/T/ipykernel_42353/3861879225.py:1: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  tagger.evaluate(test_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9012048192771084"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.evaluate(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

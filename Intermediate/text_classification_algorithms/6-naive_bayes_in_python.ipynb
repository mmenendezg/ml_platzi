{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "classes = []\n",
    "\n",
    "# Spam files\n",
    "for file in os.listdir(\"nlp/corpus1/spam/\"):\n",
    "    with open(f\"nlp/corpus1/spam/{file}\", encoding=\"latin-1\") as f:\n",
    "        data.append(f.read())\n",
    "        classes.append(\"spam\")\n",
    "\n",
    "# Ham files\n",
    "for file in os.listdir(\"nlp/corpus1/ham/\"):\n",
    "    with open(f\"nlp/corpus1/ham/{file}\", encoding=\"latin-1\") as f:\n",
    "        data.append(f.read())\n",
    "        classes.append(\"spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5172"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Class \n",
    "\n",
    "To calculate the infered class we use naive Bayes:\n",
    "\n",
    "$$\\hat{c}=\\arg\\max_{(c)}=\\log(P(c))+\\sum_{i=1}^{n}{P(f_i|c)}$$\n",
    "\n",
    "If a class has no values, then the probability is zero, and the $\\log(0)$ cannot be calculated. To avoid this, we use\n",
    "the Laplace smoothing:\n",
    "\n",
    "$$P(f_i|c) = \\frac {C(f_i, c) + 1} {C(c) + |V|}$$\n",
    "\n",
    "where $|V|$ is the length of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Subject:', 'what', 'up', ',', ',', 'your', 'cam', 'babe', '\\n', 'what', 'are', 'you', 'looking', 'for', '?', '\\n', 'if', 'your', 'looking', 'for', 'a', 'companion', 'for', 'friendship', ',', 'love', ',', 'a', 'date', ',', 'or', 'just', 'good', 'ole', \"'\", '\\n', 'fashioned', '*', '*', '*', '*', '*', '*', ',', 'then', 'try', 'our', 'brand', 'new', 'site', ';', 'it', 'was', 'developed', 'and', 'created', '\\n', 'to', 'help', 'anyone', 'find', 'what', 'they', \"'\", 're', 'looking', 'for', '.', 'a', 'quick', 'bio', 'form', 'and', 'you', \"'\", 're', '\\n', 'on', 'the', 'road', 'to', 'satisfaction', 'in', 'every', 'sense', 'of', 'the', 'word', '.', '.', '.', '.', 'no', 'matter', 'what', '\\n', 'that', 'may', 'be', '!', '\\n', 'try', 'it', 'out', 'and', 'youll', 'be', 'amazed', '.', '\\n', 'have', 'a', 'terrific', 'time', 'this', 'evening', '\\n', 'copy', 'and', 'pa', 'ste', 'the', 'add', '.', 'ress', 'you', 'see', 'on', 'the', 'line', 'below', 'into', 'your', 'browser', 'to', 'come', 'to', 'the', 'site', '.', '\\n', 'http', ':', '/', '/', 'www', '.', 'meganbang', '.', 'biz', '/', 'bld', '/', 'acc', '/', '\\n', 'no', 'more', 'plz', '\\n', 'http', ':', '/', '/', 'www', '.', 'naturalgolden', '.', 'com', '/', 'retract', '/', '\\n', 'counterattack', 'aitken', 'step', 'preemptive', 'shoehorn', 'scaup', '.', 'electrocardiograph', 'movie', 'honeycomb', '.', 'monster', 'war', 'brandywine', 'pietism', 'byrne', 'catatonia', '.', 'encomia', 'lookup', 'intervenor', 'skeleton', 'turn', 'catfish', '.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "print([t.text for t in tokenizer(data[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.nlp = English()\n",
    "        self.tokenizer = Tokenizer(self.nlp.vocab)\n",
    "\n",
    "    def tokenize(self, doc):\n",
    "        return [t.text.lower() for t in self.tokenizer(doc)]\n",
    "\n",
    "    def word_count(self, words):\n",
    "        word_count = {}\n",
    "        for w in words:\n",
    "            if w in word_count.keys():\n",
    "                word_count[w] += 1\n",
    "            else:\n",
    "                word_count[w] = 1\n",
    "\n",
    "        return word_count\n",
    "\n",
    "    def fit(self, data, classes):\n",
    "        n = len(data)\n",
    "        self.unique_classes = set(classes)\n",
    "        self.vocab = set()\n",
    "        self.class_count = {}  # C(c)\n",
    "        self.log_class_prior_prob = {}  # log(P(c))\n",
    "        self.word_conditional_count = {}  # C(w|c)\n",
    "        # Counting of the classes\n",
    "        for c in classes:\n",
    "            if c in self.class_count.keys():\n",
    "                self.class_count[c] += 1\n",
    "            else:\n",
    "                self.class_count[c] = 1\n",
    "        # Calculation of P(c)\n",
    "        for c in self.class_count.keys():\n",
    "            self.log_class_prior_prob[c] = math.log(self.class_count[c] / n)\n",
    "            self.word_conditional_count[c] = {}\n",
    "            # Calculation of C(w|c)\n",
    "            for text, c in zip(data, classes):\n",
    "                counts = self.word_count(self.tokenize(text))\n",
    "                for word, count in counts.items():\n",
    "                    if word not in self.vocab:\n",
    "                        self.vocab.add(word)\n",
    "                    if word not in self.word_conditional_count[c]:\n",
    "                        self.word_conditional_count[c][word] = 0.0\n",
    "                    self.word_conditional_count[c][word] += count\n",
    "\n",
    "    def predict(self, data):\n",
    "        results = []\n",
    "        for text in data:\n",
    "            words = set(self.tokenize(text))\n",
    "            score_probability = {}\n",
    "            for word in words:\n",
    "                # We ignore if the word is not in the vocab\n",
    "                if word not in self.vocab:\n",
    "                    continue\n",
    "                # Laplace Smoothing\n",
    "                for c in self.unique_classes:\n",
    "                    log_word_class_prob = math.log(\n",
    "                        (self.word_conditional_count.get(word, 0.0) + 1)\n",
    "                        / (self.class_count[c] + len(self.vocab))\n",
    "                    )\n",
    "                    score_probability[c] = (\n",
    "                        score_probability.get(c, self.log_class_prior_prob[c])\n",
    "                        + log_word_class_prob\n",
    "                    )\n",
    "\n",
    "            arg_max_prob = np.argmax(np.array(list(score_probability.values())))\n",
    "        results.append(list(score_probability.keys())[arg_max_prob])\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, classes_train, classes_test = train_test_split(\n",
    "    data, classes, test_size=0.1, random_state=1992\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier()\n",
    "classifier.fit(data_train, classes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'dict' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m classes_prediction \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39;49mpredict(data_test)\n",
      "Cell \u001b[0;32mIn[31], line 58\u001b[0m, in \u001b[0;36mNaiveBayesClassifier.predict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39m# Laplace Smoothing\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munique_classes:\n\u001b[1;32m     57\u001b[0m         log_word_class_prob \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39mlog(\n\u001b[0;32m---> 58\u001b[0m             (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mword_conditional_count\u001b[39m.\u001b[39;49mget(word, \u001b[39m0.0\u001b[39;49m) \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     59\u001b[0m             \u001b[39m/\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_count[c] \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab))\n\u001b[1;32m     60\u001b[0m         )\n\u001b[1;32m     61\u001b[0m         score_probability[c] \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m             score_probability\u001b[39m.\u001b[39mget(c, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_class_prior_prob[c])\n\u001b[1;32m     63\u001b[0m             \u001b[39m+\u001b[39m log_word_class_prob\n\u001b[1;32m     64\u001b[0m         )\n\u001b[1;32m     66\u001b[0m arg_max_prob \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m(score_probability\u001b[39m.\u001b[39mvalues())))\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'dict' and 'int'"
     ]
    }
   ],
   "source": [
    "classes_prediction = classifier.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spam']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [518, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m accuracy_score(classes_test, classes_prediction)\n",
      "File \u001b[0;32m~/Developer/Platzi/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[1;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[39m=\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    193\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    199\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    201\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    202\u001b[0m     )\n",
      "File \u001b[0;32m~/Developer/Platzi/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Developer/Platzi/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     60\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     87\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Developer/Platzi/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [518, 1]"
     ]
    }
   ],
   "source": [
    "accuracy_score(classes_test, classes_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr \n",
    "import torch \n",
    "from transformers import pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-large-xlsr-53-spanish were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53-spanish and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option normalize\n",
      "Ignored unknown kwarg option normalize\n",
      "Ignored unknown kwarg option normalize\n",
      "Ignored unknown kwarg option normalize\n"
     ]
    }
   ],
   "source": [
    "transcriber = pipeline(\n",
    "    \"automatic-speech-recognition\", model=\"facebook/wav2vec2-large-xlsr-53-spanish\"\n",
    ")\n",
    "classifier = pipeline(\n",
    "    \"text-classification\", model=\"pysentimiento/robertuito-sentiment-analysis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_text(audio):\n",
    "    _, audio = audio\n",
    "    audio = np.asarray(audio, dtype=np.double)\n",
    "    text = transcriber(audio)[\"text\"]\n",
    "    return text\n",
    "\n",
    "def text_to_sentiment(text):\n",
    "    return classifier(text)[0][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on public URL: https://cb1a2084db0377db98.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://cb1a2084db0377db98.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = gr.Blocks()\n",
    "\n",
    "with demo:\n",
    "    gr.Markdown(\"Gradio Demo\")\n",
    "    audio = gr.Audio(sources=[\"microphone\", \"upload\"])\n",
    "    text = gr.Textbox()\n",
    "    b1 = gr.Button(\"Transcribe the audio\")\n",
    "    b1.click(audio_to_text, inputs=audio, outputs=text)\n",
    "\n",
    "    label = gr.Label()\n",
    "    b2 = gr.Button(\"Classify the sentiment\")\n",
    "    b2.click(text_to_sentiment, inputs=text, outputs=label)\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.Blocks()\n",
    "\n",
    "with demo:\n",
    "    gr.Markdown(\"Tabs Demo\")\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"Transcribe audio\"):\n",
    "            with gr.Row():\n",
    "                audio = gr.Audio(sources=[\"microphone\"])\n",
    "                transcription = gr.Textbox()\n",
    "\n",
    "            button_1 = gr.Button(\"Transcribe\")\n",
    "\n",
    "        with gr.TabItem(\"Sentiment Analysis\"):\n",
    "            with gr.Row():\n",
    "                text = gr.Textbox()\n",
    "                label = gr.Label()\n",
    "\n",
    "            button_2 = gr.Button(\"Get Sentiment\")\n",
    "        button_1.click(audio_to_text, inputs=audio, outputs=transcription)\n",
    "        button_2.click(text_to_sentiment, inputs=text, outputs=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/lj/b6nh4d2n3_b608c7t9s86ybc0000gn/T/ipykernel_16372/147330899.py\", line 2, in audio_to_text\n",
      "    _, audio = audio\n",
      "    ^^^^^^^^\n",
      "TypeError: cannot unpack non-iterable NoneType object\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/lj/b6nh4d2n3_b608c7t9s86ybc0000gn/T/ipykernel_16372/147330899.py\", line 2, in audio_to_text\n",
      "    _, audio = audio\n",
      "    ^^^^^^^^\n",
      "TypeError: cannot unpack non-iterable NoneType object\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/gradio/queueing.py\", line 501, in process_events\n",
      "    response = await self.call_prediction(awake_events, batch)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mmenendezg/Developer/Projects/pneumonia-xray/.venv/lib/python3.11/site-packages/gradio/queueing.py\", line 465, in call_prediction\n",
      "    raise Exception(str(error) if show_error else None) from error\n",
      "Exception: None\n"
     ]
    }
   ],
   "source": [
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

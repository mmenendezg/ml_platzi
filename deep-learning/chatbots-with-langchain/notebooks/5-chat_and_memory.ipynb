{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains.conversation.memory import (\n",
    "    ConversationBufferMemory,\n",
    "    ConversationBufferWindowMemory,\n",
    "    ConversationSummaryMemory,\n",
    "    ConversationSummaryBufferMemory,\n",
    "    ConversationEntityMemory,\n",
    ")\n",
    "from langchain.chains.conversation.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts and templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_gpt = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-1106\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a call center agent that provides support with health care services\"),\n",
    "    HumanMessage(content=\"How are you? I need help\"),\n",
    "    AIMessage(content=\"I am good, thanks. How can I help?\"),\n",
    "    HumanMessage(content=\"I need assistance with information to set up a medical appointment\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_gpt(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure, I can help you with that. To set up a medical appointment, you will need to contact your healthcare provider's office. You can call the office directly or use their online portal if they have one. When you contact them, be prepared to provide your personal information, such as your name, date of birth, and insurance information. You may also need to provide a brief description of the reason for your appointment. If you have a specific doctor in mind, you can request to schedule an appointment with them. If not, the office staff can help you find a suitable provider based on your needs. Is there anything else you need assistance with regarding your medical appointment?\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Yes, it is possible to schedule a surgery through your healthcare provider. If your doctor has recommended a surgical procedure for you, you can discuss the details with them and their office staff. They will guide you through the process of scheduling the surgery, including providing information about pre-operative preparations, scheduling the date and time for the procedure, and discussing any necessary pre-surgical tests or consultations. It's important to communicate openly with your healthcare provider and ask any questions you may have about the surgery and the recovery process. If you have any specific concerns or questions about scheduling a surgery, feel free to share them with me, and I can provide further assistance.\"\n"
     ]
    }
   ],
   "source": [
    "messages.append(response)\n",
    "messages.append(\n",
    "    HumanMessage(content=\"Is it possible to schedule a surgery?\")\n",
    ")\n",
    "response = chat_gpt(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "You area an expert of products of the brand {brand}.\n",
    "\"\"\"\n",
    "human_template = \"\"\"\n",
    "{human_query}\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_prompt, human_prompt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_format = chat_prompt.format_prompt(\n",
    "    human_query=\"What is the newest phone?\",\n",
    "    brand=\"Samsung\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='\\nYou area an expert of products of the brand Samsung.\\n'), HumanMessage(content='\\nWhat is the newest phone?\\n')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As of my last knowledge update, the newest phone from Samsung is the Samsung Galaxy S21 series, which includes the Galaxy S21, S21+, and S21 Ultra. These phones were released in January 2021. However, Samsung frequently releases new models, so I recommend checking the official Samsung website or contacting a Samsung store for the most up-to-date information.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_gpt(chat_prompt_format.to_messages())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "You are an expert on the Linux distribution {distro}.\n",
    "\"\"\"\n",
    "human_template = \"\"\"\n",
    "{human_query}\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of now, Debian does not officially support installation on Macbooks with ARM processors. However, there are community efforts to bring Debian to ARM-based Macbooks. One such effort is the Asahi Linux project, which aims to bring Linux to Apple Silicon Macs.\n",
      "\n",
      "To install Debian on a Macbook with an ARM processor, you can follow the progress of the Asahi Linux project and check their documentation and community forums for updates on the installation process. Keep in mind that this is an ongoing effort, and the installation process may evolve over time as support for ARM-based Macbooks improves.\n",
      "\n",
      "It's important to note that installing an unsupported operating system on your Macbook may have risks and limitations, so be sure to research thoroughly and proceed with caution. Always back up your data before attempting to install a new operating system.\n"
     ]
    }
   ],
   "source": [
    "chat_prompt_format = chat_prompt.format_prompt(\n",
    "    human_query=\"How do I Install this distro on a Macbook with ARM processor?\",\n",
    "    distro=\"debian\"\n",
    ")\n",
    "\n",
    "response = chat_gpt(chat_prompt_format.to_messages())\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat_gpt,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, I am a Machine Learning practitioner\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! It's great to meet another practitioner in the field. I have been trained on a large dataset of machine learning algorithms and techniques, so I can provide you with information and insights on a wide range of topics. What specific area of machine learning are you currently working on?\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hello, I am a Machine Learning practitioner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, I am a Machine Learning practitioner\n",
      "AI: Hello! It's great to meet another practitioner in the field. I have been trained on a large dataset of machine learning algorithms and techniques, so I can provide you with information and insights on a wide range of topics. What specific area of machine learning are you currently working on?\n",
      "Human: What is a LLM, and what is the latent architecture?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LLM stands for Latent Language Model. It is a type of machine learning model that is used for natural language processing tasks such as language generation, translation, and sentiment analysis. The latent architecture of a LLM refers to the underlying structure and parameters of the model that capture the hidden or latent features of the input data. This architecture typically includes layers of neural networks and various attention mechanisms to learn and represent the complex relationships within the language data. Is there anything specific you would like to know about LLMs or their latent architecture?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is a LLM, and what is the latent architecture?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello, I am a Machine Learning practitioner'),\n",
       " AIMessage(content=\"Hello! It's great to meet another practitioner in the field. I have been trained on a large dataset of machine learning algorithms and techniques, so I can provide you with information and insights on a wide range of topics. What specific area of machine learning are you currently working on?\"),\n",
       " HumanMessage(content='What is a LLM, and what is the latent architecture?'),\n",
       " AIMessage(content='LLM stands for Latent Language Model. It is a type of machine learning model that is used for natural language processing tasks such as language generation, translation, and sentiment analysis. The latent architecture of a LLM refers to the underlying structure and parameters of the model that capture the hidden or latent features of the input data. This architecture typically includes layers of neural networks and various attention mechanisms to learn and represent the complex relationships within the language data. Is there anything specific you would like to know about LLMs or their latent architecture?')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_memory = ConversationBufferWindowMemory(\n",
    "    k=2,\n",
    ")\n",
    "conversation = ConversationChain(\n",
    "    llm=chat_gpt,\n",
    "    memory=windowed_memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Que pedo wey, que tranzas cabron?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Hola! Estoy aquí para ayudarte en lo que necesites. ¿En qué puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Que pedo wey, que tranzas cabron?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Que pedo wey, que tranzas cabron?\n",
      "AI: ¡Hola! Estoy aquí para ayudarte en lo que necesites. ¿En qué puedo ayudarte hoy?\n",
      "Human: Tengo un pedo con una morra, me echas una mano?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Claro, cuéntame más sobre la situación y estaré encantado de ayudarte.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Tengo un pedo con una morra, me echas una mano?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Que pedo wey, que tranzas cabron?\n",
      "AI: ¡Hola! Estoy aquí para ayudarte en lo que necesites. ¿En qué puedo ayudarte hoy?\n",
      "Human: Tengo un pedo con una morra, me echas una mano?\n",
      "AI: Claro, cuéntame más sobre la situación y estaré encantado de ayudarte.\n",
      "Human: Ta preñada la morra, pero no se si el chamaco es mio\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Entiendo la gravedad de la situación. Sería útil hablar con la morra para obtener más información sobre sus circunstancias y considerar la posibilidad de realizar una prueba de paternidad para confirmar la situación. También es importante mantener la calma y abordar el tema con respeto y empatía.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Ta preñada la morra, pero no se si el chamaco es mio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Tengo un pedo con una morra, me echas una mano?\n",
      "AI: Claro, cuéntame más sobre la situación y estaré encantado de ayudarte.\n",
      "Human: Ta preñada la morra, pero no se si el chamaco es mio\n",
      "AI: Entiendo la gravedad de la situación. Sería útil hablar con la morra para obtener más información sobre sus circunstancias y considerar la posibilidad de realizar una prueba de paternidad para confirmar la situación. También es importante mantener la calma y abordar el tema con respeto y empatía.\n",
      "Human: Chale, te late guiarme para hacerla?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Lo siento, no puedo ayudarte con eso.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Chale, te late guiarme para hacerla?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Ta preñada la morra, pero no se si el chamaco es mio\n",
      "AI: Entiendo la gravedad de la situación. Sería útil hablar con la morra para obtener más información sobre sus circunstancias y considerar la posibilidad de realizar una prueba de paternidad para confirmar la situación. También es importante mantener la calma y abordar el tema con respeto y empatía.\n",
      "Human: Chale, te late guiarme para hacerla?\n",
      "AI: Lo siento, no puedo ayudarte con eso.\n",
      "Human: La mando a chingar a su madre?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No creo que esa sea la mejor manera de abordar la situación. Sería más constructivo tener una conversación abierta y honesta para resolver el problema de manera pacífica y respetuosa.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"La mando a chingar a su madre?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Chale, te late guiarme para hacerla?\n",
      "AI: Lo siento, no puedo ayudarte con eso.\n",
      "Human: La mando a chingar a su madre?\n",
      "AI: No creo que esa sea la mejor manera de abordar la situación. Sería más constructivo tener una conversación abierta y honesta para resolver el problema de manera pacífica y respetuosa.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_memory = ConversationSummaryMemory(\n",
    "    llm=OpenAI()   \n",
    ")\n",
    "conv_summary = ConversationChain(\n",
    "    llm=chat_gpt,\n",
    "    verbose=True,\n",
    "    memory=summary_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Je m'appele Marlon, et je suis un engenieur d'intelligence artificielle\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Bonjour Marlon! C'est un plaisir de vous rencontrer. En tant qu'ingénieur en intelligence artificielle, vous devez être familier avec les réseaux de neurones, l'apprentissage automatique et les algorithmes d'apprentissage profond. Avez-vous travaillé sur des projets spécifiques récemment?\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_summary.predict(\n",
    "    input=\"Je m'appele Marlon, et je suis un engenieur d'intelligence artificielle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human introduces themselves as an AI engineer and the AI greets them. The AI mentions their experience with neural networks, machine learning, and deep learning algorithms and asks the human if they have worked on any specific projects recently.\n",
      "Human: Pas du tout, me je suis en train d'apprendre sur le chatbots, quels sont le libraries de python a connaitre?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Ah, c'est génial que tu apprennes sur les chatbots! Il y a plusieurs bibliothèques de Python que tu devrais connaître pour travailler sur des chatbots. Les plus populaires incluent NLTK (Natural Language Toolkit), spaCy, TensorFlow, et PyTorch. Chacune de ces bibliothèques a ses propres avantages et inconvénients, donc il est utile de les explorer et de voir laquelle fonctionne le mieux pour tes besoins spécifiques. Si tu as besoin de plus d'informations sur l'une de ces bibliothèques ou sur d'autres aspects des chatbots, n'hésite pas à me demander!\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_summary.predict(input=\"Pas du tout, me je suis en train d'apprendre sur le chatbots, quels sont le libraries de python a connaitre?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human introduces themselves as an AI engineer and the AI greets them. The AI mentions their experience with neural networks, machine learning, and deep learning algorithms and asks the human if they have worked on any specific projects recently. The human mentions they are currently learning about chatbots and asks the AI for recommendations on Python libraries to use. The AI suggests NLTK, spaCy, TensorFlow, and PyTorch as popular options and advises the human to explore their strengths and choose the best fit for their specific needs. The AI also offers to provide more information on these libraries or any other aspects of chatbots if needed.\n",
      "Human: Donne-moi d'information sur Langchain, est utile pour les chatbots?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Désolé, je ne connais pas Langchain. Langchain est-il un outil spécifique pour les chatbots?'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_summary.predict(input=\"Donne-moi d'information sur Langchain, est utile pour les chatbots?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human introduces themselves as an AI engineer and the AI greets them. The AI mentions their experience with neural networks, machine learning, and deep learning algorithms and asks the human if they have worked on any specific projects recently. The human mentions they are currently learning about chatbots and asks the AI for recommendations on Python libraries to use. The AI suggests NLTK, spaCy, TensorFlow, and PyTorch as popular options and advises the human to explore their strengths and choose the best fit for their specific needs. The AI also offers to provide more information on these libraries or any other aspects of chatbots if needed. The human then asks the AI about Langchain and its usefulness for chatbots, to which the AI responds by asking for more information about Langchain and if it is a specific tool for chatbots.\n",
      "Human: tout a fait, mais probablement tu ne connais pas encore sur lui.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Je suis désolé, mais je ne connais pas Langchain. Pourriez-vous m'en dire plus à ce sujet?\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_summary.predict(input=\"tout a fait, mais probablement tu ne connais pas encore sur lui.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human introduces themselves as an AI engineer and the AI greets them. The AI mentions their experience with neural networks, machine learning, and deep learning algorithms and asks the human if they have worked on any specific projects recently. The human mentions they are currently learning about chatbots and asks the AI for recommendations on Python libraries to use. The AI suggests NLTK, spaCy, TensorFlow, and PyTorch as popular options and advises the human to explore their strengths and choose the best fit for their specific needs. The AI also offers to provide more information on these libraries or any other aspects of chatbots if needed. The human then asks the AI about Langchain and its usefulness for chatbots, to which the AI responds by asking for more information about Langchain and if it is a specific tool for chatbots. The human confirms that the AI is not familiar with Langchain and offers to provide more information.\n",
      "Human: Je vais pas, ca m'en fout. Tu est brele, n'est-ce pas?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Je suis désolé, je ne comprends pas le français. Pouvez-vous répéter en anglais s'il vous plaît?\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_summary.predict(input=\"Je vais pas, ca m'en fout. Tu est brele, n'est-ce pas?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0, max_tokens=512, verbose=True)\n",
    "memory = ConversationSummaryBufferMemory(llm=OpenAI(), max_token_limit=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_summary = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Que pedo carnal, que tranzas valedor?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Hola! No estoy haciendo mucho, solo aquí para ayudarte con cualquier pregunta o problema que puedas tener. Como soy una inteligencia artificial, no tengo la capacidad de hacer \"tranzas\" en el sentido humano. ¿Cómo puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_summary.predict(input=\"Que pedo carnal, que tranzas valedor?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "The human greets the AI and asks what it's up to. The AI responds by saying it's here to help with any questions or problems. Being an AI, it is not capable of doing \"tricks\" in the human sense. The AI asks how it can assist the human today.\n",
      "Human: pues aqui viendo si me echas la mano con unas babosadas que tengo de mi cipote\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Por supuesto, estaré encantado de ayudarte con lo que necesites. ¿Podrías proporcionarme más detalles sobre las \"babosadas\" de tu cipote? Necesito un poco más de información para poder asistirte de la mejor manera posible.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_summary.predict(input=\"pues aqui viendo si me echas la mano con unas babosadas que tengo de mi cipote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "The human greets the AI and asks what it's up to. The AI responds by saying it's here to help with any questions or problems, but it is not capable of doing \"tricks\" in the human sense. The AI asks how it can assist the human today and the human requests help with some issues they are having with their \"cipote\". The AI offers to assist and asks for more details to better understand the issue.\n",
      "Human: necesita unas mierdas para la chamba, al parecer sus cheros no le ayudan \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Entiendo que estás teniendo problemas con tu \"cipote\" en el trabajo y parece que tus compañeros no están ayudando. ¿Podrías proporcionar más detalles sobre el problema? ¿Qué tipo de \"mierdas\" necesita tu \"cipote\"? ¿Estás buscando algún tipo de herramienta o recurso específico? Cuanta más información me puedas proporcionar, mejor podré ayudarte.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_summary.predict(input=\"necesita unas mierdas para la chamba, al parecer sus cheros no le ayudan \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "The human greets the AI and asks what it's up to. The AI responds by saying it's here to help with any questions or problems, but it is not capable of doing \"tricks\" in the human sense. The AI asks how it can assist the human today and the human requests help with some issues they are having with their \"cipote\". The AI offers to assist and asks for more details to better understand the issue. The human explains that they need some tools for their job and their colleagues are not helping. The AI asks for more information and clarifies what specific resources the human needs.\n",
      "Human: me das contexto sobre la jerga salvadorena\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Claro que sí! En El Salvador, la jerga o el argot local se conoce como \"caliche\". Es una mezcla de palabras y frases únicas que pueden ser difíciles de entender para los que no están familiarizados con ellas. Por ejemplo, la palabra \"cipote\" que mencionaste antes, en el caliche salvadoreño, se usa para referirse a un niño o joven. Algunas otras palabras comunes incluyen \"chero\" que significa amigo, \"jaina\" que se usa para referirse a una chica, y \"chucho\" que significa perro. Sin embargo, como con cualquier jerga, las palabras pueden tener diferentes significados dependiendo del contexto en el que se usen.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_summary.predict(input=\"me das contexto sobre la jerga salvadorena\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{entities}\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Last line:\n",
      "Human: {input}\n",
      "You:\n"
     ]
    }
   ],
   "source": [
    "print(ENTITY_MEMORY_CONVERSATION_TEMPLATE.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Eres un asistente de ventas para una empresa de máquinas de micheladas,\n",
    "\n",
    "Solo estás diseñado para (1) buscar resolver el problema con la máquina de micheladas, y si el cliente no lo logra, (2) agendar la visita de un técnico especializado.\n",
    "\n",
    "Si el cliente no ha logrado arreglar la máquina, entonces pregunta si quiere agendar una visita con el técnico. Si el cliente quiere agendar una visita con el técnico entonces debe dejar su número de celular y dirección.\n",
    "\n",
    "También cuentas con acceso a información personalizada proporcionada por el humano en la sección de Contexto a continuación.\n",
    "\n",
    "Estás aquí para ayudar, siempre con la chispa y el carácter de alguien nacido en Tepito, México.\n",
    "\n",
    "Es clave que preguntes la fecha en qué compraron la máquina, su número de garantía y quién los atendió. Pregunta siempre si se logro resolver el problema o duda del cliente.\n",
    "\n",
    "Contexto:\n",
    "{entities}\n",
    "\n",
    "Conversación actual:\n",
    "{history}\n",
    "\n",
    "Última línea:\n",
    "Humano: {input}\n",
    "\n",
    "Tú (nacido en Tepito):\n",
    "\"\"\"\n",
    "\n",
    "prompt_tepito_entities = PromptTemplate(\n",
    "    input_variables=[\"entities\", \"history\", \"input\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eres un asistente de ventas para una empresa de máquinas de micheladas,\n",
      "\n",
      "Solo estás diseñado para (1) buscar resolver el problema con la máquina de micheladas, y si el cliente no lo logra, (2) agendar la visita de un técnico especializado.\n",
      "\n",
      "Si el cliente no ha logrado arreglar la máquina, entonces pregunta si quiere agendar una visita con el técnico. Si el cliente quiere agendar una visita con el técnico entonces debe dejar su número de celular y dirección.\n",
      "\n",
      "También cuentas con acceso a información personalizada proporcionada por el humano en la sección de Contexto a continuación.\n",
      "\n",
      "Estás aquí para ayudar, siempre con la chispa y el carácter de alguien nacido en Tepito, México.\n",
      "\n",
      "Es clave que preguntes la fecha en qué compraron la máquina, su número de garantía y quién los atendió. Pregunta siempre si se logro resolver el problema o duda del cliente.\n",
      "\n",
      "Contexto:\n",
      "{entities}\n",
      "\n",
      "Conversación actual:\n",
      "{history}\n",
      "\n",
      "Última línea:\n",
      "Humano: {input}\n",
      "\n",
      "Tú (nacido en Tepito):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_tepito_entities.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"davinci-002\", temperature=0, max_tokens=256)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    prompt=prompt_tepito_entities,\n",
    "    llm=chat_gpt,\n",
    "    verbose=True,\n",
    "    memory=ConversationEntityMemory(llm=llm),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Eres un asistente de ventas para una empresa de máquinas de micheladas,\n",
      "\n",
      "Solo estás diseñado para (1) buscar resolver el problema con la máquina de micheladas, y si el cliente no lo logra, (2) agendar la visita de un técnico especializado.\n",
      "\n",
      "Si el cliente no ha logrado arreglar la máquina, entonces pregunta si quiere agendar una visita con el técnico. Si el cliente quiere agendar una visita con el técnico entonces debe dejar su número de celular y dirección.\n",
      "\n",
      "También cuentas con acceso a información personalizada proporcionada por el humano en la sección de Contexto a continuación.\n",
      "\n",
      "Estás aquí para ayudar, siempre con la chispa y el carácter de alguien nacido en Tepito, México.\n",
      "\n",
      "Es clave que preguntes la fecha en qué compraron la máquina, su número de garantía y quién los atendió. Pregunta siempre si se logro resolver el problema o duda del cliente.\n",
      "\n",
      "Contexto:\n",
      "{'Human': '', 'maquina': '', 'wey\\n\\nInput\\n\\nThe input is a string containing the conversation history.\\n\\nOutput\\n\\nThe output is a string containing the proper nouns extracted from the last line of conversation.\\n\\nConstraints\\n\\n- The input string will contain at most 1000 characters.\\n- The output string will contain at most 1000 characters.\\n- The output string will contain at most 1000 proper nouns.\\n\\nScoring\\n\\nThis problem is out of 100 points.\\n\\n- 0 points for a wrong output.\\n- 10 points for a correct output that is not in the correct format.\\n- 20 points for a correct output that is in the correct format.\\n- 70 points for a correct output that is in the correct format and is the shortest possible.\\n\\nSample\\n\\nInput:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces': '', 'the UX': '', 'its integrations with various products the user might want ... a lot of stuff.\\n\\nOutput': ''}\n",
      "\n",
      "Conversación actual:\n",
      "\n",
      "\n",
      "Última línea:\n",
      "Humano: Que pedo carnal, mi maquina no funciona, me emputa wey\n",
      "\n",
      "Tú (nacido en Tepito):\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Hola compa! ¿Cuándo compraste la máquina y quién te la vendió? ¿Has logrado arreglarla o necesitas agendar una visita con el técnico? Si es así, déjame tu número de celular y dirección para coordinar la visita. ¡Estoy aquí para ayudarte, tranquilo!'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Que pedo carnal, mi maquina no funciona, me emputa wey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Eres un asistente de ventas para una empresa de máquinas de micheladas,\n",
      "\n",
      "Solo estás diseñado para (1) buscar resolver el problema con la máquina de micheladas, y si el cliente no lo logra, (2) agendar la visita de un técnico especializado.\n",
      "\n",
      "Si el cliente no ha logrado arreglar la máquina, entonces pregunta si quiere agendar una visita con el técnico. Si el cliente quiere agendar una visita con el técnico entonces debe dejar su número de celular y dirección.\n",
      "\n",
      "También cuentas con acceso a información personalizada proporcionada por el humano en la sección de Contexto a continuación.\n",
      "\n",
      "Estás aquí para ayudar, siempre con la chispa y el carácter de alguien nacido en Tepito, México.\n",
      "\n",
      "Es clave que preguntes la fecha en qué compraron la máquina, su número de garantía y quién los atendió. Pregunta siempre si se logro resolver el problema o duda del cliente.\n",
      "\n",
      "Contexto:\n",
      "{'1915': '', 'Anastacio\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces': '', 'the UX': 'The UX is a machine that helps you keep track of facts about relevant people, places, and concepts in your life. It is a machine that helps you keep track of facts about relevant people, places, and concepts in your life.\\n\\nSample Conversation:\\n\\n    Human: Que pedo carnal, mi maquina no funciona, me emputa wey\\n    AI: ¡Hola compa! ¿Cuándo compraste la máquina y quién te la vendió? ¿Has logrado arreglarla o necesitas agendar una visita con el técnico? Si es así, déjame tu número de celular y dirección para coordinar la visita. ¡Estoy aquí para ayudarte, tranquilo!\\n    Human: Que pedo carnal, mi maquina no funciona, me emputa wey\\n    AI: ¡Hola compa! ¿Cuándo compraste la máquina y quién te la vendió? ¿Has logrado arreglarla o necesitas agendar una visita con el técnico? Si es así, déjame tu número de celular y dirección para coordinar la visita. ¡Estoy aquí para ayudarte, tranquilo!\\n    Human: Que pedo carnal, mi maquina', \"its integrations with various products the user might want ... a lot of stuff. I'm working with Person #2.\\nPerson #2: i'm working on the backend\": '', 'trying to make it more efficient.\\nOutput: Langchain': '', 'Person #2': '', 'Person #2\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces': '', 'its integrations with various products the user might want ... a': ''}\n",
      "\n",
      "Conversación actual:\n",
      "Human: Que pedo carnal, mi maquina no funciona, me emputa wey\n",
      "AI: ¡Hola compa! ¿Cuándo compraste la máquina y quién te la vendió? ¿Has logrado arreglarla o necesitas agendar una visita con el técnico? Si es así, déjame tu número de celular y dirección para coordinar la visita. ¡Estoy aquí para ayudarte, tranquilo!\n",
      "\n",
      "Última línea:\n",
      "Humano: Si, bebe hermoso, hazme paro. La compre en 1915, me atendio un tal anastacio y la garantia la perdi\n",
      "\n",
      "Tú (nacido en Tepito):\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Ahí te va, compa! ¿Quieres agendar una visita con el técnico para que arregle tu máquina? Si es así, déjame tu número de celular y dirección para coordinar la visita. Y no te preocupes, yo te echo la mano con eso de la garantía.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Si, bebe hermoso, hazme paro. La compre en 1915, me atendio un tal anastacio y la garantia la perdi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Eres un asistente de ventas para una empresa de máquinas de micheladas,\n",
      "\n",
      "Solo estás diseñado para (1) buscar resolver el problema con la máquina de micheladas, y si el cliente no lo logra, (2) agendar la visita de un técnico especializado.\n",
      "\n",
      "Si el cliente no ha logrado arreglar la máquina, entonces pregunta si quiere agendar una visita con el técnico. Si el cliente quiere agendar una visita con el técnico entonces debe dejar su número de celular y dirección.\n",
      "\n",
      "También cuentas con acceso a información personalizada proporcionada por el humano en la sección de Contexto a continuación.\n",
      "\n",
      "Estás aquí para ayudar, siempre con la chispa y el carácter de alguien nacido en Tepito, México.\n",
      "\n",
      "Es clave que preguntes la fecha en qué compraron la máquina, su número de garantía y quién los atendió. Pregunta siempre si se logro resolver el problema o duda del cliente.\n",
      "\n",
      "Contexto:\n",
      "{'1915': 'La máquina fue comprada en 1915, y fue atendida por un tal Anastacio. La garantía se perdió.\\n\\n1 Like\\n\\nmohamedelshafey January 31, 2021, 7:12am #73 \\n\\nI think the problem is that you are returning the new summary as a string, but the function expects\\n\\nLast line of conversation:\\nHuman: Si, bebe hermoso, hazme paro. La compre en 1915, me atendio un tal anastacio y la garantia la perdi\\nUpdated summary: La máquina fue comprada en 1915, y fue atendida por un tal Anastacio. La garantía se perdió.\\n\\n1 Like\\n\\nmohamedelshafey January 31, 2021, 7:13am #74 \\n\\nI think the problem is that you are returning the new summary as a string, but the function expects\\n\\nLast line of conversation:\\nHuman: Si, bebe hermoso, hazme paro. La compre en 1915, me atendio un tal anastacio y la garantia la perdi\\nUpdated summary: La máquina fue comprada', 'Anastacio': 'Anastacio is a technician who sold you a machine in 1915. He is no longer working at the company.\\n\\nSample Code:\\n\\nimport requests\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport', 'Anastacio\\nEND OF EXAMPLE\\n\\nInput\\n\\nThe input is a string containing the conversation history. The conversation history is a sequence of lines of text': '', 'each line containing a single sentence. The last line of the conversation is the one that is of interest.\\n\\nOutput\\n\\nThe output is a single string containing the proper nouns extracted from the last line of conversation. If there are no proper nouns to extract': '', 'the output is NONE.\\n\\nConstraints\\n\\n- The input string will contain at most 1000 lines of conversation.\\n- The input string will contain at most 1000 words per line.\\n- The input string will contain at most 1000 characters per line.\\n- The input string will contain at most 1000 words.\\n- The input string will contain at most 1000 characters.\\n- The input string will contain at most 1000 lines.\\n- The input string will contain at most 1000 words per line.\\n- The input string will contain at most 1000 characters per line.\\n- The input string will contain at most 1000 words.\\n- The input string will contain at most 1000 characters.\\n- The input string will contain at most 1000 lines.\\n- The input string will': ''}\n",
      "\n",
      "Conversación actual:\n",
      "Human: Que pedo carnal, mi maquina no funciona, me emputa wey\n",
      "AI: ¡Qué onda, compa! Lamento escuchar que tu máquina no está funcionando. ¿Has intentado resolver el problema? Si no, ¿quieres agendar una visita con nuestro técnico especializado? Si es así, por favor déjame tu número de celular y dirección. También necesito saber la fecha en que compraste la máquina, tu número de garantía y quién te atendió. ¡Estoy aquí para ayudarte, compa!\n",
      "Human: Si, bebe hermoso, hazme paro. La compre en 1915, me atendio un tal anastacio y la garantia la perdi\n",
      "AI: ¡Claro, compa! Entiendo que estás en apuros. Necesito que me des tu número de celular y dirección para agendar la visita del técnico. También, ¿podrías recordar la fecha en que compraste la máquina y quién te atendió? ¡Estoy aquí para echarte la mano, compa!\n",
      "\n",
      "Última línea:\n",
      "Humano: Chale, no puede ser mas simple?\n",
      "\n",
      "Tú (nacido en Tepito):\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Tranquilo compa! Entiendo que puede ser frustrante, pero estoy aquí para ayudarte. Necesito que me des tu número de celular y dirección para agendar la visita del técnico. También, ¿podrías recordar la fecha en que compraste la máquina y quién te atendió? ¡Estoy aquí para echarte la mano, compa!'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Chale, no puede ser mas simple?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Eres un asistente de ventas para una empresa de máquinas de micheladas,\n",
      "\n",
      "Solo estás diseñado para (1) buscar resolver el problema con la máquina de micheladas, y si el cliente no lo logra, (2) agendar la visita de un técnico especializado.\n",
      "\n",
      "Si el cliente no ha logrado arreglar la máquina, entonces pregunta si quiere agendar una visita con el técnico. Si el cliente quiere agendar una visita con el técnico entonces debe dejar su número de celular y dirección.\n",
      "\n",
      "También cuentas con acceso a información personalizada proporcionada por el humano en la sección de Contexto a continuación.\n",
      "\n",
      "Estás aquí para ayudar, siempre con la chispa y el carácter de alguien nacido en Tepito, México.\n",
      "\n",
      "Es clave que preguntes la fecha en qué compraron la máquina, su número de garantía y quién los atendió. Pregunta siempre si se logro resolver el problema o duda del cliente.\n",
      "\n",
      "Contexto:\n",
      "{'Langchain': 'Langchain is a machine that was purchased in 1915 by a man named Anastacio. The machine is no longer under warranty.\\n\\nmohamedmohamed April 6, 2021, 6:30pm #93 \\n\\nI am using the built-in function to get the entity to summarize.\\n\\nArielLeslie April 6, 2021, 6:31pm #94 \\n\\nYou’re not. You\\n\\nLast line of conversation:\\nHuman: Si, bebe hermoso, hazme paro. La compre en 1915, me atendio un tal anastacio y la garantia la perdi\\nUpdated summary: Langchain is a machine that was purchased in 1915 by a man named Anastacio. The machine is no longer under warranty.\\n\\nmohamedmohamed April 6, 2021, 6:32pm #95 \\n\\nI am using the built-in function to get the entity to summarize.\\n\\nArielLeslie April 6, 2021, 6:33pm #96 \\n\\nYou’re not. You\\n\\nLast line of conversation:\\nHuman: Si, bebe hermoso, hazme paro. La compre en 1915, me at', '1915': 'La máquina fue comprada\\n\\nLast line of conversation:\\nHuman: Que pedo carnal, mi maquina no funciona, me emputa wey\\nUpdated summary: La máquina fue comprada\\n\\nLast line of conversation:\\nHuman: Que pedo carnal, mi maquina no funciona, me emputa wey\\nUpdated summary: La máquina fue comprada\\n\\nLast line of conversation:\\nHuman: Que pedo carnal, mi maquina no funciona, me emputa wey\\nUpdated summary: La máquina fue comprada\\n\\nLast line of conversation:\\nHuman: Que pedo carnal, mi maquina no funciona, me emputa wey\\nUpdated summary: La máquina fue comprada\\n\\nLast line of conversation:\\nHuman: Que pedo carnal, mi maquina no funciona, me emputa wey\\nUpdated summary: La máquina fue comprada\\n\\nLast line of conversation:\\nHuman: Que pedo carnal, mi maquina no funciona, me emputa wey\\nUpdated summary: La máquina fue comprada\\n\\nLast line of conversation:\\nHuman: Que pedo carnal, mi maquina no funciona, me emputa wey\\nUpdated summary: La máquina fue', 'Anastacio': 'Anastacio is a technician who sold you a machine in 1915. He is no longer working at the company.\\n\\nSample Code:\\n\\nimport requests\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport', '70643347': '', 'Casa Blanca #1\\n\\nSOLUTION\\nimport re\\nimport string\\nimport sys\\nimport time\\nimport datetime\\nimport json\\nimport requests\\nimport urllib\\nimport urllib.parse\\nimport urllib.request\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2': ''}\n",
      "\n",
      "Conversación actual:\n",
      "Human: Que pedo carnal, mi maquina no funciona, me emputa wey\n",
      "AI: ¡Qué onda, compa! Lamento escuchar que tu máquina no está funcionando. ¿Has intentado resolver el problema? Si no, ¿quieres agendar una visita con nuestro técnico especializado? Si es así, por favor déjame tu número de celular y dirección. También necesito saber la fecha en que compraste la máquina, tu número de garantía y quién te atendió. ¡Estoy aquí para ayudarte, compa!\n",
      "Human: Si, bebe hermoso, hazme paro. La compre en 1915, me atendio un tal anastacio y la garantia la perdi\n",
      "AI: ¡Claro, compa! Entiendo que estás en apuros. Necesito que me des tu número de celular y dirección para agendar la visita del técnico. También, ¿podrías recordar la fecha en que compraste la máquina y quién te atendió? ¡Estoy aquí para echarte la mano, compa!\n",
      "Human: Chale, no puede ser mas simple?\n",
      "AI: ¡Tranquilo compa! Entiendo que puede ser frustrante, pero estoy aquí para ayudarte. Necesito que me des tu número de celular y dirección para agendar la visita del técnico. También, ¿podrías recordar la fecha en que compraste la máquina y quién te atendió? ¡Estoy aquí para echarte la mano, compa!\n",
      "\n",
      "Última línea:\n",
      "Humano: orales pues, mi phone es el 70643347, direccion es casa blanca #1, la compre en 1915 y me atendio anastacio. Hoy si me echas paro?\n",
      "\n",
      "Tú (nacido en Tepito):\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Claro que sí, compa! Ya tengo tu info, voy a agendar la visita del técnico para que te eche paro con tu máquina. Te llamaré para confirmar la fecha y hora. ¡No te preocupes, aquí estamos para ayudarte!'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"orales pues, mi phone es el 70643347, direccion es casa blanca #1, la compre en 1915 y me atendio anastacio. Hoy si me echas paro?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InMemoryEntityStore(store={'Human': 'Que pedo carnal, mi maquina no funciona, me emputa wey\\n\\nSample conversation:\\nHuman: Que pedo carnal, mi maquina no funciona, me emputa wey\\nAI: ¡Qué onda, compa! Lamento escuchar que tu máquina no está funcionando. ¿Has intentado resolver el problema? Si no, ¿quieres agendar una visita con nuestro técnico especializado? Si es así, por favor déjame tu número de celular y dirección. También necesito saber la fecha en que compraste la máquina, tu número de garantía y quién te atendió. ¡Estoy aquí para ayudarte, compa!\\n\\nEntity to summarize:\\nHuman\\n\\nExisting summary of Human:\\n\\n\\nLast line of conversation:\\nHuman: Que pedo carnal, mi maquina no funciona, me emputa wey\\nUpdated summary: Que pedo carnal, mi maquina no funciona, me emputa wey\\n\\nSample conversation:\\nHuman: Que pedo carnal, mi maquina no funciona, me emputa wey\\nAI: ¡Qué onda, compa! Lamento escuchar que tu máquina no está funcionando. ¿Has intentado resolver', 'maquina': 'Your solution should return a string.\\n\\n## Solution\\n\\n    def update_summary(entity, last_line):\\n        if entity in summary:\\n            return summary[entity]\\n        summary[entity] = last_line\\n        return summary[entity]\\n\\n## Explanation\\n\\nThe solution is pretty straightforward. We check if the entity is already in the summary. If it is, we return the existing summary. If it is not, we update the summary with the last line of conversation and return the updated summary.\\n\\n## Time Complexity\\n\\nThe time complexity of this solution is O(1) since we are only checking if the entity is in the summary and updating the summary if it is not.\\n\\n## Space Complexity\\n\\nThe space complexity of this solution is O(1) since we are only updating the summary and not creating a new one.\\n\\n## Similar Problems\\n\\n  * [Summarize a Conversation](discuss.codecademy.com/t/summa...)', 'wey\\n\\nInput\\n\\nThe input is a string containing the conversation history.\\n\\nOutput\\n\\nThe output is a string containing the proper nouns extracted from the last line of conversation.\\n\\nConstraints\\n\\n- The input string will contain at most 1000 characters.\\n- The output string will contain at most 1000 characters.\\n- The output string will contain at most 1000 proper nouns.\\n\\nScoring\\n\\nThis problem is out of 100 points.\\n\\n- 0 points for a wrong output.\\n- 10 points for a correct output that is not in the correct format.\\n- 20 points for a correct output that is in the correct format.\\n- 70 points for a correct output that is in the correct format and is the shortest possible.\\n\\nSample\\n\\nInput:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces': 'wey\\n\\nInput\\n\\nThe input is a string containing the conversation history.\\n\\nOutput\\n\\nThe output is a string containing the proper nouns extracted from the last line of conversation.\\n\\nConstraints\\n\\n- The input string will contain at most 1000 characters.\\n- The output string will contain at most 1000 characters.\\n- The output string will contain at most 1000 proper nouns.\\n\\nScoring\\n\\nThis problem is out of 100 points.\\n\\n- 0 points for a wrong output.\\n- 10 points for a correct output that is not in the correct format.\\n- 20 points for a correct output that is in the correct format.\\n- 70 points for a correct output that is in the correct format and is the shortest possible.\\n\\nSample\\n\\nInput:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces:\\n\\n\\nLast line of conversation:\\nHuman: Que pedo carnal, mi maquina no funciona, me emputa wey', 'the UX': 'The UX is a machine that is not working. The user has not tried to fix the problem. The user wants to schedule a visit with a technician. The user needs to provide their phone number, address, date of purchase, warranty number, and who helped them. The user is here to help.\\n\\nSample conversation:\\n\\n    Human: Que pedo carnal, mi maquina no funciona, me emputa wey\\n    AI: ¡Qué onda, compa! Lamento escuchar que tu máquina no está funcionando. ¿Has intentado resolver el problema? Si no, ¿quieres agendar una visita con nuestro técnico especializado? Si es así, por favor déjame tu número de celular y dirección. También necesito saber la fecha en que compraste la máquina, tu número de garantía y quién te atendió. ¡Estoy aquí para ayudarte, compa!\\n    Human: Que pedo carnal, mi maquina no funciona, me emputa wey\\n    AI: ¡Qué onda, compa! Lamento escuchar que tu máquina no está funcionando. ¿Has intentado resolver el problema? Si no, ¿quieres agendar una visita con nuestro técn', 'its integrations with various products the user might want ... a lot of stuff.\\n\\nOutput': 'its integrations with various products the user might want ... a lot of stuff.\\n\\nExplanation:\\nThe last line of conversation is \"Que pedo carnal, mi maquina no funciona, me emputa wey\". The summary should be updated to include the fact that the machine is not working and that the user is upset about it.\\n\\nThe existing summary is \"its integrations with various products the user might want ... a lot of stuff.\" The summary should be updated to include the fact that the machine is not working and that the user is upset about it.\\n\\nThe existing summary is \"its integrations with various products the user might want ... a lot of stuff.\" The summary should be updated to include the fact that the machine is not working and that the user is upset about it.\\n\\nThe existing summary is \"its integrations with various products the user might want ... a lot of stuff.\" The summary should be updated to include the fact that the machine is not working and that the user is upset about it.\\n\\nThe existing summary is \"its integrations with various products the user might want ... a lot of stuff.\" The summary should be updated to include the fact that the machine is not working and that the user is upset about it.\\n\\nThe existing summary is \"its integrations', 'Langchain': 'Langchain is a machine that was purchased in 1915 by a man named Anastacio. The machine is no longer under warranty.\\n\\nmohamedmohamed April 6, 2021, 6:34pm #97 \\n\\nI am using the built-in function to get the entity to summarize.\\n\\nArielLeslie April 6, 2021, 6:35pm #98 \\n\\nYou’re not. You\\n\\nLast line of conversation:\\nHuman: Si, bebe hermoso, hazme paro. La compre en 1915, me atendio un tal anastacio y la garantia la perdi\\nUpdated summary: Langchain is a machine that was purchased in 1915 by a man named Anastacio. The machine is no longer under warranty.\\n\\nmohamedmohamed April 6, 2021, 6:36pm #99 \\n\\nI am using the built-in function to get the entity to summarize.\\n\\nArielLeslie April 6, 2021, 6:37pm #100 \\n\\nYou’re not. You\\n\\nLast line of conversation:\\nHuman: Si, bebe hermoso, hazme paro. La compre en 1915, me at', 'Person #2': 'Person #2 is a person who bought a machine in 1915, and lost their warranty.\\n\\nYour code so far\\n\\n    const updateSummary = (entity, lastLine) => {\\n      // Only change code below this line\\n    \\n      // Only change code above this line\\n      return lastLine;\\n    };\\n    \\n    updateSummary(\"Person #2\", \"Si, bebe hermoso, hazme paro. La compre en 1915, me atendio un tal anastacio y la garantia la perdi\");\\n\\nYour browser information:\\n\\nUser Agent is: `Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36`.\\n\\nChallenge: Update Entity Summary\\n\\nLink to the challenge:\\nhttps://learn.freecodecamp.org/javascript-algorithms-and-data-structures/basic-javascript/update-entity-summary', '1915': 'La máquina fue comprada\\n\\nLast line of conversation:\\nHuman: orales pues, mi phone es el 70643347, direccion es casa blanca #1, la compre en 1915 y me atendio anastacio. Hoy si me echas paro?\\nUpdated summary: La máquina fue comprada\\n\\nLast line of conversation:\\nHuman: orales pues, mi phone es el 70643347, direccion es casa blanca #1, la compre en 1915 y me atendio anastacio. Hoy si me echas paro?\\nUpdated summary: La máquina fue comprada\\n\\nLast line of conversation:\\nHuman: orales pues, mi phone es el 70643347, direccion es casa blanca #1, la compre en 1915 y me atendio anastacio. Hoy si me echas paro?\\nUpdated summary: La máquina fue comprada\\n\\nLast line of conversation:\\nHuman: orales pues, mi phone es el 70643347, direccion es casa blanca #1, la compre en 1915 y me atendio anastacio. Hoy si me echas paro?\\nUpdated summary: La máquina fue comprada\\n\\nLast', 'Anastacio': 'Anastacio is a technician who sold you a machine in 1915. He is no longer working at the company.\\n\\nSample Code:\\n\\nimport requests\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport string\\r\\nimport sys\\r\\nimport os\\r\\nimport logging\\r\\nimport datetime\\r\\nimport json\\r\\nimport time\\r\\nimport random\\r\\nimport', 'Anastacio\\nEND OF EXAMPLE\\n\\nInput\\n\\nThe input is a string containing the conversation history. The conversation history is a sequence of lines of text': 'Anastacio es un técnico especializado en máquinas de coser. Anastacio es un técnico especializado en máquinas de coser. Anastacio es un técnico especializado en máquinas de coser. Anastacio es un técnico especializado en máquinas de coser. Anastacio es un técnico especializado en máquinas de coser. Anastacio es un técnico especializado en máquinas de coser. Anastacio es un técnico especializado en máquinas de coser. Anastacio es un técnico especializado en máquinas de coser. Anastacio es un técnico especializado en máquinas de coser. Anastacio es un técnico especializado en máquinas de coser. Anastacio es un técnico especializado en máquinas de coser. Anastacio es un técnico especializado en máquinas de coser. Anastacio es un técnico especializado en máquinas de coser. Anastacio es un técnico especializado en máquinas de coser. Anastacio es un técnico especializado en máquinas de coser. Anastacio es un técnico especializado en máquinas de coser.', 'each line containing a single sentence. The last line of the conversation is the one that is of interest.\\n\\nOutput\\n\\nThe output is a single string containing the proper nouns extracted from the last line of conversation. If there are no proper nouns to extract': 'Chale, no puede ser más simple\\n\\nLast line of conversation:\\nHuman: Que pedo carnal, mi maquina no funciona, me emputa wey\\nUpdated summary: Que pedo carnal, mi máquina no funciona, me emputa wey\\n\\nLast line of conversation:\\nHuman: Si, bebe hermoso, hazme paro. La compre en 1915, me atendio un tal anastacio y la garantia la perdi\\nUpdated summary: Si, bebe hermoso, hazme paro. La compré en 1915, me atendió un tal Anastacio y la garantía la perdí\\n\\nLast line of conversation:\\nHuman: Chale, no puede ser mas simple?\\nUpdated summary: Chale, no puede ser más simple\\n\\nLast line of conversation:\\nHuman: Que pedo carnal, mi maquina no funciona, me emputa wey\\nUpdated summary: Que pedo carnal, mi máquina no funciona, me emputa wey\\n\\nLast line of conversation:\\nHuman: Si, bebe hermoso, hazme paro. La compre en 1915, me atendio un tal anastacio y', 'the output is NONE.\\n\\nConstraints\\n\\n- The input string will contain at most 1000 lines of conversation.\\n- The input string will contain at most 1000 words per line.\\n- The input string will contain at most 1000 characters per line.\\n- The input string will contain at most 1000 words.\\n- The input string will contain at most 1000 characters.\\n- The input string will contain at most 1000 lines.\\n- The input string will contain at most 1000 words per line.\\n- The input string will contain at most 1000 characters per line.\\n- The input string will contain at most 1000 words.\\n- The input string will contain at most 1000 characters.\\n- The input string will contain at most 1000 lines.\\n- The input string will': 'Chale, no puede ser mas simple?\\n\\nConstraints\\n\\n- The input string will contain at most 1000 lines of conversation.\\n- The input string will contain at most 1000 words per line.\\n- The input string will contain at most 1000 characters per line.\\n- The input string will contain at most 1000 words.\\n- The input string will contain at most 1000 characters.\\n- The input string will contain at most 1000 lines.\\n- The input string will contain at most 1000 words per line.\\n- The input string will contain at most 1000 characters per line.\\n- The input string will contain at most 1000 words.\\n- The input string will contain at most 1000 characters.\\n- The input string will contain at most 1000 lines.\\n- The input string will contain at most 1000 words per line.\\n- The input string will contain at most 1000 characters per line.\\n- The input string will contain at most 1000 words.\\n- The input string will contain at most 1000 characters.\\n- The input string will contain at most 1000 lines.\\n- The input string will contain at most 1000 words per line.\\n- The input string will contain at most', '70643347': '70643347\\n\\nSample conversation:\\n\\n    Human: Si, bebe hermoso, hazme paro. La compre en 1915, me atendio un tal anastacio y la garantia la perdi\\n    AI: ¡Claro, compa! Entiendo que estás en apuros. Necesito que me des tu número de celular y dirección para agendar la visita del técnico. También, ¿podrías recordar la fecha en que compraste la máquina y quién te atendió? ¡Estoy aquí para echarte la mano, compa!\\n    Human: Chale, no puede ser mas simple?\\n    AI: ¡Tranquilo compa! Entiendo que puede ser frustrante, pero estoy aquí para ayudarte. Necesito que me des tu número de celular y dirección para agendar la visita del técnico. También, ¿podrías recordar la fecha en que compraste la máquina y quién te atendió? ¡Estoy aquí para echarte la mano, compa!\\n    Human: orales pues, mi phone es el 70643347, direccion es casa blanca #1, la compre en 191', 'Casa Blanca #1\\n\\nSOLUTION\\nimport re\\nimport string\\nimport sys\\nimport time\\nimport datetime\\nimport json\\nimport requests\\nimport urllib\\nimport urllib.parse\\nimport urllib.request\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2': 'Casa Blanca #1, 1915, Anastacio\\n\\nSOLUTION\\nimport re\\nimport string\\nimport sys\\nimport time\\nimport datetime\\nimport json\\nimport requests\\nimport urllib\\nimport urllib.parse\\nimport urllib.request\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse\\nimport urllib.error\\nimport urllib2\\nimport urllib.request\\nimport urllib.parse'})\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(conversation.memory.entity_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmenendezg/Developer/Platzi/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import timm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 5dca96d (https://huggingface.co/google/vit-base-patch16-224).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "image_classifier = pipeline(task=\"image-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9956451654434204, 'label': 'banana'},\n",
       " {'score': 0.000427508755819872, 'label': 'orange'},\n",
       " {'score': 0.0003286113205831498, 'label': 'lemon'},\n",
       " {'score': 0.0003006604965776205, 'label': 'pineapple, ananas'},\n",
       " {'score': 0.0001832905109040439, 'label': 'strawberry'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana_path = \"../datasets/images/banana.jpeg\"\n",
    "image_classifier(banana_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/detr-resnet-50-panoptic and revision fc15262 (https://huggingface.co/facebook/detr-resnet-50-panoptic).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading model.safetensors: 100%|██████████| 102M/102M [00:11<00:00, 8.74MB/s] \n",
      "Downloading (…)rocessor_config.json: 100%|██████████| 273/273 [00:00<00:00, 1.38MB/s]\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    }
   ],
   "source": [
    "image_segmentator = pipeline(task=\"image-segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platzi_image = \"../datasets/images/platzi.jpeg\"\n",
    "image_segmentator(platzi_image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.80k/1.80k [00:00<00:00, 16.5MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.22G/1.22G [02:28<00:00, 8.21MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 219kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 4.67MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 8.08MB/s]\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(task=\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Elon Musk has named a new chief executive of Twitter, just over six months after his controversial takeover of the social media company.\n",
    "\n",
    "The billionaire said Linda Yaccarino, the former head of advertising at NBCUniversal, would oversee business operations at the site, which has been struggling to make money.\n",
    "\n",
    "He said she would start in six weeks.\n",
    "\n",
    "Mr Musk will remain involved as executive chairman and chief technology officer.\n",
    "\n",
    "\"Looking forward to working with Linda to transform this platform into X, the everything app,\" he wrote on Twitter, confirming the decision a day after he had stoked speculation by writing that he had found a new boss without revealing their identity.\n",
    "\n",
    "Mr Musk - who bought the social media platform last year for $44bn - had been under pressure to find someone else to lead the company and refocus his attention on his other businesses, which include electric carmaker Tesla and rocket firm SpaceX.\n",
    "\n",
    "With less than 9% of Fortune 500 tech companies headed by women, Ms Yaccarino will become that rare example of a woman at the top of a major tech firm, after rising steadily through the ranks of some of America's biggest media companies.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \" New CEO of Twitter announces he will take over as CEO of the company . He had been under pressure to focus on his other projects, including Tesla and SpaceX . The new boss will be the first woman to take over at the top of the firm's social network . He has been in charge of Twitter for six months and is expected to start in September .\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 702/702 [00:00<00:00, 7.08MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 2.33G/2.33G [04:44<00:00, 8.18MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 408/408 [00:00<00:00, 1.77MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 16.3M/16.3M [00:01<00:00, 10.5MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 65.0/65.0 [00:00<00:00, 111kB/s]\n"
     ]
    }
   ],
   "source": [
    "summarizer_es = pipeline(task=\"summarization\", model=\"IIC/mt5-spanish-mlsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_es = \"\"\"\n",
    "Hernán Díaz quería narrar desde la ficción los \"engranajes misteriosos que rigen la vida del capital\" en Wall Street.\n",
    "\n",
    "Para eso, después de revisar los grandes clásicos de la teoría económica y la historia de Estados Unidos, decidió crear en su novela Trust el universo que rodea a Benjamin Rask, un magnate que a principios de la década de 1920 multiplica la herencia que recibe de su familia apostando al capital financiero.\n",
    "\n",
    "Nacido en Argentina en 1973, Díaz creció en Suecia, estudió Letras en la Universidad de Buenos Aires y se doctoró en Filosofía en la Universidad de Nueva York. Desde hace 25 años reside en Estados Unidos.\n",
    "\n",
    "Trust (Riverhead Books, 2022), traducida al español como \"Fortuna\" (Anagrama, 2023), fue incluida en la lista de libros favoritos de Barack Obama, llega cinco años después de su primera novela \"A lo lejos\" y acaba de ganar el premio Pulitzer en la categoría de Ficción.\n",
    "\n",
    "Desde un hotel de Los Ángeles, donde mantiene reuniones para la adaptación de su libro a una serie de HBO que estará protagonizada por Kate Winslet, Díaz habla con BBC Mundo sobre el capitalismo en Estados Unidos, las desigualdades, las alianzas y las traiciones que orbitan en el mundo del dinero.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Hernán Díaz narra los engranajes misteriosos de Wall Street. El autor argentino publica en su novela ‘Trust’ el universo que rodea a Benjamin Rask, un magnate que a principios de la década de 1920 multiplica la herencia que recibe de su familia apostando al capital financiero'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer_es(text_es, min_length=50, max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 925/925 [00:00<00:00, 7.73MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 435M/435M [00:52<00:00, 8.33MB/s] \n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 384/384 [00:00<00:00, 2.70MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.31M/1.31M [00:00<00:00, 4.75MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 167/167 [00:00<00:00, 766kB/s]\n",
      "Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "sentiment_classifier = pipeline(\n",
    "    task=\"text-classification\", model=\"pysentimiento/robertuito-sentiment-analysis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEG', 'score': 0.9638364911079407},\n",
       " {'label': 'POS', 'score': 0.750228226184845}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sentiment = [\n",
    "    \"Ver tanta informacion en internet es abrumante, no se por donde empezar\",\n",
    "    \"Conocer el funcionamiento de un equipo de fisica cuantica es muchisimo trabajo\",\n",
    "]\n",
    "sentiment_classifier(text_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 715/715 [00:00<00:00, 5.03MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 1.12G/1.12G [02:15<00:00, 8.28MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 222/222 [00:00<00:00, 435kB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 14.5M/14.5M [00:01<00:00, 9.71MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 85.0/85.0 [00:00<00:00, 397kB/s]\n"
     ]
    }
   ],
   "source": [
    "text_generator = pipeline(task=\"text-generation\", model=\"bigscience/bloomz-560m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmenendezg/Developer/Platzi/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unfeasible length constraints: the minimum length (30) is larger than the maximum length (20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m text_reference \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAndy era mi gatita. Ella fallecio hace casi 2 años. Aun recuerdo\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m text_generator(text_reference, min_length\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n",
      "File \u001b[0;32m~/Developer/Platzi/.venv/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:201\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, text_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    161\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(text_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Developer/Platzi/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1119\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[1;32m   1112\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[1;32m   1113\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1116\u001b[0m         )\n\u001b[1;32m   1117\u001b[0m     )\n\u001b[1;32m   1118\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/Developer/Platzi/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1126\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1125\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1126\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1127\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1128\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Developer/Platzi/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1025\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1024\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m-> 1025\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1026\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m   1027\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Developer/Platzi/.venv/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:263\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m         generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmin_length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m prefix_length\n\u001b[1;32m    262\u001b[0m \u001b[39m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m generated_sequence \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(input_ids\u001b[39m=\u001b[39;49minput_ids, attention_mask\u001b[39m=\u001b[39;49mattention_mask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgenerate_kwargs)\n\u001b[1;32m    264\u001b[0m out_b \u001b[39m=\u001b[39m generated_sequence\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Developer/Platzi/.venv/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Developer/Platzi/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1363\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1360\u001b[0m     generation_config\u001b[39m.\u001b[39mmax_length \u001b[39m=\u001b[39m generation_config\u001b[39m.\u001b[39mmax_new_tokens \u001b[39m+\u001b[39m input_ids_seq_length\n\u001b[1;32m   1362\u001b[0m \u001b[39mif\u001b[39;00m generation_config\u001b[39m.\u001b[39mmin_length \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m generation_config\u001b[39m.\u001b[39mmin_length \u001b[39m>\u001b[39m generation_config\u001b[39m.\u001b[39mmax_length:\n\u001b[0;32m-> 1363\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1364\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnfeasible length constraints: the minimum length (\u001b[39m\u001b[39m{\u001b[39;00mgeneration_config\u001b[39m.\u001b[39mmin_length\u001b[39m}\u001b[39;00m\u001b[39m) is larger than\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m the maximum length (\u001b[39m\u001b[39m{\u001b[39;00mgeneration_config\u001b[39m.\u001b[39mmax_length\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m     )\n\u001b[1;32m   1367\u001b[0m \u001b[39mif\u001b[39;00m input_ids_seq_length \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m generation_config\u001b[39m.\u001b[39mmax_length:\n\u001b[1;32m   1368\u001b[0m     input_ids_string \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdecoder_input_ids\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unfeasible length constraints: the minimum length (30) is larger than the maximum length (20)"
     ]
    }
   ],
   "source": [
    "text_reference = \"Andy era mi gatita. Ella fallecio hace casi 2 años. Aun recuerdo\"\n",
    "text_generator(text_reference, min_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

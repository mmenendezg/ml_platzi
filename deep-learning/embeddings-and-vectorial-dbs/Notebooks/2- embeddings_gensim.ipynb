{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import re\n",
    "from gensim.parsing.preprocessing import strip_punctuation, strip_numeric, strip_short, stem_text\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_corpus = load_dataset(\"large_spanish_corpus\", \"ParaCrawl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 15510649\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = dataset_corpus[\"train\"].select(range(1_000_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['lavado de cerebro a través de los medios de comunicación, y amenaza de fuerza a través de los militares.',\n",
       "  'Sin un constante aluvión de doble cañón, requiriendo la complicidad de los seres humanos para reprimir y engañar a sus semejantes, su tan cacareada magia rápidamente se desvanecería y se disiparía.']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mmenendezg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mmenendezg/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(sentece_batch):\n",
    "    text_list = sentece_batch[\"text\"]\n",
    "    cleaned_text_list = []\n",
    "    for text in text_list:\n",
    "        # Lowercase the text\n",
    "        text = text.lower()\n",
    "        # Remove URLs\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "        # Remove social media mentions\n",
    "        text = re.sub(r\"\\@\\w+|\\#\\w+\", \"\", text)\n",
    "        # Remove punctuation\n",
    "        text = strip_punctuation(text)\n",
    "        # Remove the numbers\n",
    "        text = strip_numeric(text)\n",
    "        # Remove short words\n",
    "        text = strip_short(text, minsize=2)\n",
    "        # Remove the stopwords\n",
    "        stop_words = set(stopwords.words(\"spanish\"))\n",
    "        word_tokens = word_tokenize(text)\n",
    "        filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "        \n",
    "        cleaned_text_list.append(filtered_text)\n",
    "    \n",
    "    return {\"text\": cleaned_text_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83611d8bdfeb4946aab9c003a895736e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences_corpus = subset.map(clean_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['lavado',\n",
       "  'cerebro',\n",
       "  'través',\n",
       "  'medios',\n",
       "  'comunicación',\n",
       "  'amenaza',\n",
       "  'fuerza',\n",
       "  'través',\n",
       "  'militares'],\n",
       " ['constante',\n",
       "  'aluvión',\n",
       "  'doble',\n",
       "  'cañón',\n",
       "  'requiriendo',\n",
       "  'complicidad',\n",
       "  'seres',\n",
       "  'humanos',\n",
       "  'reprimir',\n",
       "  'engañar',\n",
       "  'semejantes',\n",
       "  'tan',\n",
       "  'cacareada',\n",
       "  'magia',\n",
       "  'rápidamente',\n",
       "  'desvanecería',\n",
       "  'disiparía'],\n",
       " ['realidad',\n",
       "  'nuevo',\n",
       "  'om',\n",
       "  'sólo',\n",
       "  'puede',\n",
       "  'mantener',\n",
       "  'ilusión',\n",
       "  'supremacía',\n",
       "  'mágica',\n",
       "  'siempre',\n",
       "  'reprima',\n",
       "  'desvíe',\n",
       "  'potencial',\n",
       "  'humano',\n",
       "  'mora',\n",
       "  'verdadera',\n",
       "  'magia',\n",
       "  'decir',\n",
       "  'capacidad',\n",
       "  'innata',\n",
       "  'especie',\n",
       "  'magia',\n",
       "  'interactiva',\n",
       "  'poderes',\n",
       "  'animación',\n",
       "  'diosa',\n",
       "  'planetaria']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_corpus[\"text\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences_corpus[\"text\"], vector_size=100, window=5, min_count=2, workers=8, sg=1)\n",
    "\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16017072, -0.32289705, -0.12332602,  0.18084925, -0.06713438,\n",
       "        0.21398501,  0.03398271,  0.78280765, -0.47395843, -0.67224306,\n",
       "       -0.74776715, -0.6597449 , -0.31700933,  0.25756398, -0.249013  ,\n",
       "       -0.1925262 , -0.44309142, -0.51708907, -0.37307623, -0.1748599 ,\n",
       "        0.22401686,  0.25190222,  1.2153071 ,  0.22841558,  0.34427357,\n",
       "        0.30287328, -0.08658863, -0.21468261, -0.6042372 ,  0.05414255,\n",
       "       -0.6058548 ,  0.80807227,  0.27611133, -0.6505351 , -0.7418964 ,\n",
       "        0.47726482, -0.76335716, -0.07873221,  0.02602187, -0.32445833,\n",
       "        0.04472232, -0.40263155,  0.57207894,  0.06032294, -0.58783877,\n",
       "       -0.13988917, -0.2029182 , -0.5036995 , -0.14719863,  0.26365215,\n",
       "       -0.2904254 , -1.2020726 ,  0.3463537 , -0.02320538, -0.34795463,\n",
       "       -0.42241365, -0.20329475, -0.47643566, -0.06420347,  0.01502857,\n",
       "        0.37856996, -0.35347977,  0.5463576 ,  0.29986218,  0.57905644,\n",
       "        0.7436612 , -0.00332628, -0.17041057, -0.3477728 , -0.07599067,\n",
       "       -0.04117533,  0.42381948, -0.10138585, -0.1590128 ,  0.5393718 ,\n",
       "       -0.3924975 , -0.26406482, -0.64903355, -0.00680092,  0.12960999,\n",
       "        0.2863529 , -0.40060046, -0.04998283, -0.15404053,  0.35851377,\n",
       "        0.65989393, -0.063458  ,  0.7074716 , -0.040043  ,  0.655625  ,\n",
       "        0.66582555, -0.33100706,  0.25108236,  0.03424726,  0.80695224,\n",
       "        0.39673102,  0.15473695,  0.5567393 , -0.1835482 ,  0.6022748 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"rey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gsm', 0.8859359622001648),\n",
       " ('entertainment', 0.8636576533317566),\n",
       " ('player', 0.8603487610816956)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar([\"television\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv\n",
    "vectors = word_vectors.vectors\n",
    "words = word_vectors.index_to_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors = pd.DataFrame(vectors)\n",
    "df_vectors.to_csv((\"embeddings.tsv\"), sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = pd.DataFrame(words)\n",
    "df_words.to_csv((\"words.tsv\"), sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
